# ASLInterpreter

## Inspiration for this project
This project is inspired by my encounter with a customer at my part-time job. One day, a deaf man came into the store to get some help finding a product. He knew how to communicate using American Sign Language (ASL) but no one in the store was trained in ASL. As a result, we scrambled to find a good app or program that could help us communicate with him. Unfortunately, we could not find an easy resource that could help us. At that moment I thought: "Hey this is something that should exist!". From that day on, my mind kept coming back to this idea of an easy to use app or website that could interpret Sign Language using a camera.

## My Vision
I am going to take this as a massive learning opportunity to make this app. I know this can help so many people out in the world. I am going into this project having some basic data science knowledge about data wrangling, pre-processing, training, and testing. However, the models I have used have been quite simple. So that is where I will begin.

I will start this project small by using a simple model. So far, I have decided to use a SVC (subject to change). I will also begin this project very simple by only focusing on interpreting the ASL Alphabet rather than the entire langauge. Trying to tackle the whole language would be a very large task that would prove quite difficult for myself at this stage.

After I have built on this strong base, I hope to expand this to the entire ASL language! I hope to use more complex and accurate Computer Vision and Deep Learning models to further improve this project. I hope to one day have this project available as a website and a mobile app.
